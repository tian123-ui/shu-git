
#TODOå¯åŠ¨ï¼š streamlit run "äºŒã€RFM å®¢æˆ·ä»·å€¼æ¨¡å‹ï¼ˆæœºå™¨å­¦ä¹ å®ç°ï¼‰.py"


# åŸºäºPySparkçš„RFMæ¨¡å‹ä¸å•†å“åˆ†æçœ‹æ¿å®ç°
import findspark

findspark.init()

from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, sum, max, datediff, current_date, when, desc, rank
from pyspark.sql.window import Window
from pyspark.sql.types import DoubleType, IntegerType
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
import numpy as np
from datetime import datetime

import os
# é…ç½®PySparkç¯å¢ƒ
os.environ["PYSPARK_PYTHON"] = "D:\\ANACONDA\\envs\\day1\\python.exe"
os.environ["PYSPARK_DRIVER_PYTHON"] = "D:\\ANACONDA\\envs\\day1\\python.exe"


# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º
plt.rcParams["font.family"] = ["SimHei", "WenQuanYi Micro Hei", "Heiti TC"]
sns.set(font='SimHei', font_scale=0.8)


class RFMAnalyzer:
    """RFMæ¨¡å‹åˆ†æå™¨"""

    def __init__(self, spark):
        self.spark = spark
        self.transactions_df = None  # äº¤æ˜“æ•°æ®
        self.rfm_df = None  # RFMæŒ‡æ ‡æ•°æ®
        self.segmented_df = None  # å®¢æˆ·åˆ†ç¾¤æ•°æ®

    def load_data_from_path(self, data_path):
        """ä»æ–‡ä»¶è·¯å¾„åŠ è½½äº¤æ˜“æ•°æ®"""
        # å‡è®¾æ•°æ®æ ¼å¼: customer_id, order_id, order_date, amount, product_id, category
        self.transactions_df = self.spark.read.csv(
            data_path,
            header=True,
            inferSchema=True,
            timestampFormat="yyyy-MM-dd"
        )
        # ç¡®ä¿æ—¥æœŸåˆ—æ ¼å¼æ­£ç¡®
        self.transactions_df = self.transactions_df.withColumn(
            "order_date", col("order_date").cast("date")
        )
        return self

    def load_data_from_df(self, df):
        """ä»å·²æœ‰DataFrameåŠ è½½äº¤æ˜“æ•°æ®"""
        self.transactions_df = df.withColumn(
            "order_date", col("order_date").cast("date")
        )
        return self

    def calculate_rfm(self):
        """è®¡ç®—RFMæŒ‡æ ‡"""
        if self.transactions_df is None:
            raise ValueError("è¯·å…ˆåŠ è½½äº¤æ˜“æ•°æ®ï¼ˆä½¿ç”¨load_data_from_pathæˆ–load_data_from_dfï¼‰")

        # æŒ‰å®¢æˆ·IDåˆ†ç»„è®¡ç®—RFMå€¼
        self.rfm_df = self.transactions_df.groupBy("customer_id").agg(
            datediff(current_date(), max("order_date")).alias("recency"),  # æœ€è¿‘æ¶ˆè´¹æ—¶é—´
            count("order_id").alias("frequency"),  # æ¶ˆè´¹é¢‘ç‡
            sum("amount").alias("monetary")  # æ¶ˆè´¹é‡‘é¢
        )
        return self

    def score_rfm(self):
        """ä¸ºRFMæŒ‡æ ‡æ‰“åˆ†(1-5åˆ†)"""
        if self.rfm_df is None:
            self.calculate_rfm()

        # è®¡ç®—æ€»å®¢æˆ·æ•°ï¼ˆç”¨äºç™¾åˆ†æ¯”è®¡ç®—ï¼‰
        total_customers = self.rfm_df.count()

        # è®¡ç®—Råˆ† (å€¼è¶Šå°è¶Šå¥½ï¼Œæ‰€ä»¥åè½¬åˆ†æ•°)
        r_window = Window.orderBy(col("recency"))
        self.rfm_df = self.rfm_df.withColumn(
            "r_quartile",
            when(rank().over(r_window) / total_customers <= 0.2, 5)
            .when(rank().over(r_window) / total_customers <= 0.4, 4)
            .when(rank().over(r_window) / total_customers <= 0.6, 3)
            .when(rank().over(r_window) / total_customers <= 0.8, 2)
            .otherwise(1)
        )

        # è®¡ç®—Fåˆ†
        f_window = Window.orderBy(desc("frequency"))
        self.rfm_df = self.rfm_df.withColumn(
            "f_quartile",
            when(rank().over(f_window) / total_customers <= 0.2, 5)
            .when(rank().over(f_window) / total_customers <= 0.4, 4)
            .when(rank().over(f_window) / total_customers <= 0.6, 3)
            .when(rank().over(f_window) / total_customers <= 0.8, 2)
            .otherwise(1)
        )

        # è®¡ç®—Måˆ†
        m_window = Window.orderBy(desc("monetary"))
        self.rfm_df = self.rfm_df.withColumn(
            "m_quartile",
            when(rank().over(m_window) / total_customers <= 0.2, 5)
            .when(rank().over(m_window) / total_customers <= 0.4, 4)
            .when(rank().over(m_window) / total_customers <= 0.6, 3)
            .when(rank().over(m_window) / total_customers <= 0.8, 2)
            .otherwise(1)
        )

        # è®¡ç®—æ€»åˆ†
        self.rfm_df = self.rfm_df.withColumn(
            "rfm_score",
            col("r_quartile") + col("f_quartile") + col("m_quartile")
        )

        return self

    def segment_customers(self):
        """æ ¹æ®RFMåˆ†æ•°è¿›è¡Œå®¢æˆ·åˆ†ç¾¤"""
        if self.rfm_df is None:
            self.score_rfm()

        # å®šä¹‰å®¢æˆ·åˆ†ç¾¤è§„åˆ™
        self.segmented_df = self.rfm_df.withColumn(
            "segment",
            when((col("r_quartile") >= 4) & (col("f_quartile") >= 4) & (col("m_quartile") >= 4), "é«˜ä»·å€¼å®¢æˆ·")
            .when((col("r_quartile") >= 3) & (col("f_quartile") >= 4) & (col("m_quartile") >= 3), "å¿ è¯šå®¢æˆ·")
            .when((col("r_quartile") >= 4) & (col("f_quartile") <= 3) & (col("m_quartile") >= 3), "æ½œåŠ›å®¢æˆ·")
            .when((col("r_quartile") >= 3) & (col("f_quartile") >= 2) & (col("m_quartile") >= 2), "ä¸€èˆ¬å®¢æˆ·")
            .when((col("r_quartile") <= 3) & (col("f_quartile") >= 3) & (col("m_quartile") >= 3), "æµå¤±é£é™©å®¢æˆ·")
            .otherwise("æµå¤±å®¢æˆ·")
        )
        return self

    def get_segment_distribution(self):
        """è·å–å®¢æˆ·åˆ†ç¾¤åˆ†å¸ƒ"""
        if self.segmented_df is None:
            self.segment_customers()
        return self.segmented_df.groupBy("segment").count().toPandas()

    def get_rfm_stats(self):
        """è·å–å„åˆ†ç¾¤çš„RFMç»Ÿè®¡æ•°æ®"""
        if self.segmented_df is None:
            self.segment_customers()
        return self.segmented_df.groupBy("segment").agg(
            sum("monetary").alias("æ€»æ¶ˆè´¹é‡‘é¢"),
            count("customer_id").alias("å®¢æˆ·æ•°é‡"),
            avg("frequency").alias("å¹³å‡æ¶ˆè´¹é¢‘ç‡"),
            avg("recency").alias("å¹³å‡æœ€è¿‘æ¶ˆè´¹å¤©æ•°")
        ).toPandas()


class ProductAnalyzer:
    """å•†å“ä¸»é¢˜æŒ‡æ ‡åˆ†æå™¨"""

    def __init__(self, spark, transactions_df, customer_segments_df):
        self.spark = spark
        self.transactions_df = transactions_df
        self.customer_segments_df = customer_segments_df
        self.product_metrics_df = None

    def calculate_product_metrics(self):
        """è®¡ç®—å•†å“æ ¸å¿ƒæŒ‡æ ‡"""
        # åˆå¹¶äº¤æ˜“æ•°æ®å’Œå®¢æˆ·åˆ†ç¾¤æ•°æ®
        merged_df = self.transactions_df.join(
            self.customer_segments_df.select("customer_id", "segment"),
            on="customer_id",
            how="inner"
        )

        # è®¡ç®—å•†å“åŸºæœ¬æŒ‡æ ‡
        self.product_metrics_df = merged_df.groupBy("product_id", "category").agg(
            count("order_id").alias("æ€»é”€é‡"),
            sum("amount").alias("æ€»é”€å”®é¢"),
            (sum("amount") / count("order_id")).alias("å¹³å‡å®¢å•ä»·")
        )

        return self

    def get_top_products(self, n=10):
        """è·å–é”€é‡TOP Nå•†å“"""
        if self.product_metrics_df is None:
            self.calculate_product_metrics()
        return self.product_metrics_df.orderBy(desc("æ€»é”€é‡")).limit(n).toPandas()

    def get_category_sales(self):
        """è·å–å„å“ç±»é”€å”®å æ¯”"""
        if self.product_metrics_df is None:
            self.calculate_product_metrics()

        category_sales = self.product_metrics_df.groupBy("category").agg(
            sum("æ€»é”€å”®é¢").alias("å“ç±»æ€»é”€å”®é¢")
        )

        total_sales = category_sales.agg(sum("å“ç±»æ€»é”€å”®é¢")).collect()[0][0]

        return category_sales.withColumn(
            "é”€å”®å æ¯”",
            (col("å“ç±»æ€»é”€å”®é¢") / total_sales * 100).cast(DoubleType())
        ).toPandas()

    def get_segment_product_contribution(self):
        """è·å–å„å®¢æˆ·åˆ†ç¾¤å¯¹å•†å“é”€å”®çš„è´¡çŒ®"""
        merged_df = self.transactions_df.join(
            self.customer_segments_df.select("customer_id", "segment"),
            on="customer_id",
            how="inner"
        )

        return merged_df.groupBy("segment", "category").agg(
            sum("amount").alias("åˆ†ç¾¤é”€å”®é¢"),
            count("order_id").alias("åˆ†ç¾¤è®¢å•æ•°")
        ).toPandas()

    def get_sales_trend(self):
        """è·å–é”€å”®è¶‹åŠ¿"""
        return self.transactions_df.groupBy(
            col("order_date").substr(1, 7).alias("æœˆä»½")
        ).agg(
            sum("amount").alias("æœˆåº¦é”€å”®é¢"),
            count("order_id").alias("æœˆåº¦è®¢å•æ•°")
        ).orderBy("æœˆä»½").toPandas()


class Dashboard:
    """å¯è§†åŒ–çœ‹æ¿"""

    def __init__(self, rfm_analyzer, product_analyzer):
        self.rfm_analyzer = rfm_analyzer
        self.product_analyzer = product_analyzer
        self.transactions_df = None  # äº¤æ˜“æ•°æ®ï¼ˆç”¨äºæ¦‚è§ˆæŒ‡æ ‡ï¼‰
        self.setup_page()

    def setup_page(self):
        """è®¾ç½®é¡µé¢é…ç½®"""
        st.set_page_config(
            page_title="RFMå®¢æˆ·åˆ†æä¸å•†å“360çœ‹æ¿",
            page_icon="ğŸ“Š",
            layout="wide"
        )
        st.title("RFMå®¢æˆ·åˆ†æä¸å•†å“360çœ‹æ¿")

    def display_overview_metrics(self):
        """å±•ç¤ºæ¦‚è§ˆæŒ‡æ ‡"""
        if self.transactions_df is None:
            st.warning("ç¼ºå°‘äº¤æ˜“æ•°æ®ï¼Œæ— æ³•å±•ç¤ºæ¦‚è§ˆæŒ‡æ ‡")
            return

        col1, col2, col3, col4 = st.columns(4)

        # æ€»å®¢æˆ·æ•°
        total_customers = self.rfm_analyzer.segmented_df.count()
        col1.metric("æ€»å®¢æˆ·æ•°", f"{total_customers:,}")

        # æ€»é”€å”®é¢
        total_sales = self.transactions_df.agg(sum("amount")).collect()[0][0]
        col2.metric("æ€»é”€å”®é¢", f"Â¥{total_sales:,.2f}")

        # å¹³å‡è®¢å•é‡‘é¢
        avg_order_value = self.transactions_df.agg(
            sum("amount") / count("order_id")
        ).collect()[0][0]
        col3.metric("å¹³å‡è®¢å•é‡‘é¢", f"Â¥{avg_order_value:,.2f}")

        # æ€»è®¢å•æ•°
        total_orders = self.transactions_df.count()
        col4.metric("æ€»è®¢å•æ•°", f"{total_orders:,}")

    def display_rfm_analysis(self):
        """å±•ç¤ºRFMåˆ†æç»“æœ"""
        st.subheader("RFMå®¢æˆ·åˆ†ç¾¤åˆ†æ")

        # å®¢æˆ·åˆ†ç¾¤åˆ†å¸ƒ
        segment_dist = self.rfm_analyzer.get_segment_distribution()
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.barplot(x="segment", y="count", data=segment_dist, ax=ax)
        ax.set_title("å®¢æˆ·åˆ†ç¾¤åˆ†å¸ƒ")
        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)
        st.pyplot(fig)

        # RFMæ•£ç‚¹å›¾
        rfm_pd = self.rfm_analyzer.segmented_df.select(
            "recency", "frequency", "monetary", "segment"
        ).toPandas()
        fig, ax = plt.subplots(figsize=(12, 8))
        sns.scatterplot(
            x="frequency", y="monetary", hue="segment",
            size="recency", sizes=(50, 200), alpha=0.7,
            data=rfm_pd, ax=ax
        )
        ax.set_title("å®¢æˆ·æ¶ˆè´¹é¢‘ç‡ vs æ¶ˆè´¹é‡‘é¢åˆ†å¸ƒ")
        ax.set_xlabel("æ¶ˆè´¹é¢‘ç‡")
        ax.set_ylabel("æ¶ˆè´¹é‡‘é¢")
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        st.pyplot(fig)

        # å„åˆ†ç¾¤RFMç»Ÿè®¡
        st.subheader("å„å®¢æˆ·åˆ†ç¾¤RFMæŒ‡æ ‡ç»Ÿè®¡")
        rfm_stats = self.rfm_analyzer.get_rfm_stats()
        st.dataframe(rfm_stats.style.format({
            "æ€»æ¶ˆè´¹é‡‘é¢": "Â¥{:,.2f}",
            "å¹³å‡æ¶ˆè´¹é¢‘ç‡": "{:.2f}",
            "å¹³å‡æœ€è¿‘æ¶ˆè´¹å¤©æ•°": "{:.1f}"
        }))

    def display_product_analysis(self):
        """å±•ç¤ºå•†å“åˆ†æç»“æœ"""
        st.subheader("å•†å“ä¸»é¢˜æŒ‡æ ‡åˆ†æ")

        # é”€å”®è¶‹åŠ¿
        sales_trend = self.product_analyzer.get_sales_trend()
        fig, ax1 = plt.subplots(figsize=(12, 6))

        ax1.plot(sales_trend["æœˆä»½"], sales_trend["æœˆåº¦é”€å”®é¢"], 'b-', label='é”€å”®é¢')
        ax1.set_xlabel('æœˆä»½')
        ax1.set_ylabel('é”€å”®é¢', color='b')
        ax1.tick_params('y', colors='b')
        ax1.set_xticklabels(sales_trend["æœˆä»½"], rotation=45)

        ax2 = ax1.twinx()
        ax2.plot(sales_trend["æœˆä»½"], sales_trend["æœˆåº¦è®¢å•æ•°"], 'g-', label='è®¢å•æ•°')
        ax2.set_ylabel('è®¢å•æ•°', color='g')
        ax2.tick_params('y', colors='g')

        fig.tight_layout()
        st.pyplot(fig)

        # é”€é‡TOP10å•†å“
        top_products = self.product_analyzer.get_top_products(10)
        fig, ax = plt.subplots(figsize=(12, 6))
        sns.barplot(x="product_id", y="æ€»é”€é‡", data=top_products, ax=ax)
        ax.set_title("é”€é‡TOP10å•†å“")
        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)
        st.pyplot(fig)

        # å“ç±»é”€å”®å æ¯”
        category_sales = self.product_analyzer.get_category_sales()
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.pie(
            category_sales["é”€å”®å æ¯”"],
            labels=category_sales["category"],
            autopct='%1.1f%%',
            startangle=90
        )
        ax.set_title("å•†å“å“ç±»é”€å”®å æ¯”")
        st.pyplot(fig)

        # å®¢æˆ·åˆ†ç¾¤å¯¹å“ç±»é”€å”®çš„è´¡çŒ®
        segment_contribution = self.product_analyzer.get_segment_product_contribution()
        fig, ax = plt.subplots(figsize=(12, 8))
        pivot_data = segment_contribution.pivot(
            index="category", columns="segment", values="åˆ†ç¾¤é”€å”®é¢"
        )
        pivot_data.plot(kind='bar', stacked=True, ax=ax)
        ax.set_title("å„å®¢æˆ·åˆ†ç¾¤å¯¹å“ç±»é”€å”®çš„è´¡çŒ®")
        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        st.pyplot(fig)

    def show(self):
        """å±•ç¤ºå®Œæ•´çœ‹æ¿"""
        # æ¦‚è§ˆæŒ‡æ ‡
        self.display_overview_metrics()

        # RFMåˆ†æ
        self.display_rfm_analysis()

        # å•†å“åˆ†æ
        self.display_product_analysis()


def generate_sample_data(spark, num_records=10000):
    """ç”Ÿæˆæ ·æœ¬äº¤æ˜“æ•°æ®ç”¨äºæµ‹è¯•"""
    np.random.seed(42)

    # ç”Ÿæˆå®¢æˆ·ID
    customer_ids = np.random.randint(1, 1000, size=num_records)

    # ç”Ÿæˆè®¢å•æ—¥æœŸ (è¿‡å»1å¹´å†…)
    end_date = datetime.now()
    start_date = datetime(end_date.year - 1, end_date.month, end_date.day)
    date_range = (end_date - start_date).days
    order_dates = [
        (start_date + pd.Timedelta(days=np.random.randint(0, date_range))).strftime("%Y-%m-%d")
        for _ in range(num_records)
    ]

    # ç”Ÿæˆè®¢å•é‡‘é¢
    amounts = np.random.lognormal(mean=5, sigma=0.8, size=num_records)
    amounts = np.round(amounts, 2)

    # ç”Ÿæˆå•†å“IDå’Œå“ç±»
    product_ids = np.random.randint(1, 200, size=num_records)
    categories = np.random.choice(
        ["ç”µå­äº§å“", "æœè£…é‹å¸½", "é£Ÿå“é¥®æ–™", "å®¶å±…ç”¨å“", "ç¾å¦†ä¸ªæŠ¤"],
        size=num_records
    )

    # åˆ›å»ºè®¢å•ID
    order_ids = np.arange(1, num_records + 1)

    # åˆ›å»ºDataFrame
    data = {
        "order_id": order_ids,
        "customer_id": customer_ids,
        "order_date": order_dates,
        "amount": amounts,
        "product_id": product_ids,
        "category": categories
    }

    return spark.createDataFrame(pd.DataFrame(data))


def main():
    # åˆå§‹åŒ–Sparkä¼šè¯
    spark = SparkSession.builder \
        .appName("RFM Analysis and Product Dashboard") \
        .master("local[*]") \
        .getOrCreate()

    try:
        # ç”Ÿæˆæ ·æœ¬æ•°æ® (å®é™…åº”ç”¨ä¸­æ›¿æ¢ä¸ºè¯»å–çœŸå®æ•°æ®)
        st.sidebar.info("ä½¿ç”¨æ ·æœ¬æ•°æ®è¿›è¡Œåˆ†æï¼Œå®é™…åº”ç”¨ä¸­å¯æ›¿æ¢ä¸ºçœŸå®æ•°æ®æº")
        transactions_df = generate_sample_data(spark, 50000)

        # æ‰§è¡ŒRFMåˆ†æï¼ˆä½¿ç”¨DataFrameåŠ è½½æ•°æ®ï¼Œè€Œéæ–‡ä»¶è·¯å¾„ï¼‰
        rfm_analyzer = RFMAnalyzer(spark)
        rfm_analyzer.load_data_from_df(transactions_df).calculate_rfm().score_rfm().segment_customers()

        # æ‰§è¡Œå•†å“åˆ†æ
        product_analyzer = ProductAnalyzer(
            spark,
            transactions_df,
            rfm_analyzer.segmented_df
        )
        product_analyzer.calculate_product_metrics()

        # å±•ç¤ºçœ‹æ¿
        dashboard = Dashboard(rfm_analyzer, product_analyzer)
        dashboard.transactions_df = transactions_df  # ä¼ é€’äº¤æ˜“æ•°æ®ç”¨äºæ¦‚è§ˆæŒ‡æ ‡
        dashboard.show()

    finally:
        spark.stop()


if __name__ == "__main__":
    main()