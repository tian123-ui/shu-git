# 自动生成的SeaTunnel配置文件
# 源表: tms.transport_task
# 目标表: ods_transport_task
# 生成时间: 2025-07-21 21:23:30
# 提示: Hive DDL已单独生成到ddl_scripts目录

env {
  execution.parallelism = 1
  job.mode = "BATCH"
}

source {
  Jdbc {
    url = "jdbc:mysql://cdh03:3306/tms"
    driver = "com.mysql.jdbc.Driver"
    connection_check_timeout_sec = 100
    user = "root"
    password = "root"
    table_path = "tms.transport_task"
    query = "SELECT `id`, `shift_id`, `line_id`, `start_org_id`, `start_org_name`, `end_org_id`, `end_org_name`, `status`, `order_num`, `driver1_emp_id`, `driver1_name`, `driver2_emp_id`, `driver2_name`, `truck_id`, `truck_no`, `actual_start_time`, `actual_end_time`, `actual_distance`, `create_time`, `update_time`, `is_deleted`,date_format(create_time,'%Y%m%d') as ds FROM `tms`.`transport_task`"

  }
}

transform {
 
}

sink {
  Hive {
    table_name = "tms.ods_transport_task"
    metastore_uri = "thrift://cdh01:9083"
    hive.hadoop.conf-path = "/etc/hadoop/conf"
    save_mode = "overwrite"
    partition_by = ["ds"]
    dynamic_partition = true
    file_format = "orc"
    orc_compress = "SNAPPY"
    tbl_properties = {
            "external.table.purge" = "true"
        }
    fields = ['id', 'shift_id', 'line_id', 'start_org_id', 'start_org_name', 'end_org_id', 'end_org_name', 'status', 'order_num', 'driver1_emp_id', 'driver1_name', 'driver2_emp_id', 'driver2_name', 'truck_id', 'truck_no', 'actual_start_time', 'actual_end_time', 'actual_distance', 'create_time', 'update_time', 'is_deleted']
  }
}
