# 自动生成的SeaTunnel配置文件
# 源表: tms.express_task_collect
# 目标表: ods_express_task_collect
# 生成时间: 2025-07-21 21:23:29
# 提示: Hive DDL已单独生成到ddl_scripts目录

env {
  execution.parallelism = 1
  job.mode = "BATCH"
}

source {
  Jdbc {
    url = "jdbc:mysql://cdh03:3306/tms"
    driver = "com.mysql.jdbc.Driver"
    connection_check_timeout_sec = 100
    user = "root"
    password = "root"
    table_path = "tms.express_task_collect"
    query = "SELECT `id`, `order_id`, `status`, `org_id`, `org_name`, `courier_emp_id`, `courier_name`, `estimated_collected_time`, `estimated_commit_time`, `actual_collected_time`, `actual_commit_time`, `cancel_time`, `remark`, `create_time`, `update_time`, `is_deleted`,date_format(create_time,'%Y%m%d') as ds FROM `tms`.`express_task_collect`"

  }
}

transform {
 
}

sink {
  Hive {
    table_name = "tms.ods_express_task_collect"
    metastore_uri = "thrift://cdh01:9083"
    hive.hadoop.conf-path = "/etc/hadoop/conf"
    save_mode = "overwrite"
    partition_by = ["ds"]
    dynamic_partition = true
    file_format = "orc"
    orc_compress = "SNAPPY"
    tbl_properties = {
            "external.table.purge" = "true"
        }
    fields = ['id', 'order_id', 'status', 'org_id', 'org_name', 'courier_emp_id', 'courier_name', 'estimated_collected_time', 'estimated_commit_time', 'actual_collected_time', 'actual_commit_time', 'cancel_time', 'remark', 'create_time', 'update_time', 'is_deleted']
  }
}
